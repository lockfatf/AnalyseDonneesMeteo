---
title: "Rapport de Projet"
subtitle: "par Kévin Des Courières, Axel Kuehn et Florian Lock-Fat "
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Présentation du projet :

Voici notre rapport de projet sur les données météo. Nous avons travaillé à trois sur ce projet. Vous pouvez accèder aux codes sources du projet en R ainsi que le document RMarkdown et même ce rapport en PDF à l'adresse suivante : <https://github.com/lockfatf/AnalyseDonneesMeteo>.

# I. Préparations des données : 

## I.1. Importation des librairies nécéssaires :

```{r library}
pacman::p_load(data.table,tidyverse,reshape2,FactoMineR,doParallel,Matrix,
               factoextra,rgl,caret,missMDA,dplyr,ggplot2,pls,glmnet,cowplot,ggrepel)
```

## I.2. Importation des données :

Commencons par importer les jeux de données mis à notre disposition.

```{r data load}
# Chargement des donnees avec fread, plus intelligent que read.csv
# Climat
climat <- fread("Données/climat.201708.csv",data.table = F)
# Villes
villes <- fread("Données/postesSynop.csv",data.table=F)
```

Avant de faire une jointure des 2 jeux de données, Regardons les plus en détails avec un `summary()`.

```{r eval=FALSE}
# Summary
summary(climat)
summary(villes)
```

```{r merge}
# Merge des 2 jeux de données
climat <- merge(climat,villes,by="NUM_POSTE",all.x = T)
# Une ville avec aucune correspondance
climat$Nom[is.na(climat$Nom)] <- "NOM INCONNU"
# Renomage de l'indice par la variable "Nom"" 
row.names(climat) <- climat$Nom
# Elimination des variables "Nom" et "NUM_POSTE" 
climat <- climat[,-c(1,55)]
# Dimension de notre jeu de données
dim(climat)
```
Suite à la jointure des 2 jeux de données, nous avons un jeu de données de 58 observations et 56 variables.

## I.3. Nettoyage des données :

Premièrement, nous cherchons à isoler les variables avec plus de 10% de valeurs manquantes. Nous isolons ausi les variales avec une variance trop faible en prévention de la futur ACP.

```{r warning=FALSE}
# Recuperer variables avec plus de 10% de NA pour les enlever
idx_bad_col <- which(apply(climat,2,function(x){sum(is.na(x))})> (dim(climat)[1]/10))
# et les variables avec variance trop faible, probleme pour l'acp sinon
near_zero_var <- nzv(climat, freqCut = 95/5)
# et les enlever
climat_rm_na <- climat[,-c(idx_bad_col,near_zero_var)]
# Sélection des variables numériques pour PCA
climat_rm_na <- climat_rm_na %>% select_if(is_numeric)
# Dimension de notre jeu de données
dim(climat_rm_na)
```

Nous obtenons un jeu de données nettoyé avec 58 observations et 25 variables.

## I.4. Matrice de corrélation : 

Avec ce dernier jeu de données obtenu, nous allons regarder la matrice de corrélation :

```{r echo=FALSE}
# Construction de la matrice de corrélation
cormat <-  cor(climat_rm_na) %>% 
  round(2)
# Function
# Get upper triangle of the correlation matrix
get_upper_tri <- function(cormat){
  cormat[lower.tri(cormat)]<- NA
  return(cormat)
}

reorder_cormat <- function(cormat){
  # Use correlation between variables as distance
  dd <- as.dist((1-cormat)/2)
  hc <- hclust(dd)
  cormat <-cormat[hc$order, hc$order]
}

cormat[which(is.na(cormat))] <- 0
cormat <- reorder_cormat(cormat)
upper_tri <- get_upper_tri(cormat)
# Melt the correlation matrix
melted_cormat <- melt(upper_tri, na.rm = TRUE)
```

```{r fig.height=5}
# Create a ggheatmap
ggheatmap <- ggplot(melted_cormat, aes(Var2, Var1, fill = value)) +
  geom_tile(color = "white") +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                       midpoint = 0, limit = c(-1,1), space = "Lab", 
                       name="Pearson\nCorrelation") +
  theme_minimal() + # minimal theme
  theme(axis.text.x = element_text(angle = 45, vjust = 1, 
                                   size = 12, hjust = 1)) +
  coord_fixed()
# Print the heatmap
ggheatmap
```

La matrice de corrélation révèle de nombreuses corrélations entre nos variables que l'ont peut repérer et éliminer grâce à la fonction `findCorrelation()`:

```{r data clean 2}
# Annotation des variables fortement corrélées
idx_corVar = findCorrelation(cormat, cutoff = 0.5, verbose = FALSE, names = FALSE, exact = T)
```

On cherche maintenant à imputer les valeurs manquantes de notre jeu de données. Pour cela nous avons décidé d'utiliser le package `missMDA` qui a été spécifiquement implémenté pour imputer les données manquante en vue d'effectuer une analyse par ACP. Il nous faut tout d'abord estimer le nombre de composantes requises par la fonction `imputePCA` qui est la fonction permettant d'imputer ensuite les données par ACP itérative, avec le nombre de composantes optimal identifié par la fonction `estim_ncpPCA`.

```{r data imputation}
# Elimination des variables annotées
preproc <- climat_rm_na[,-idx_corVar]
# Estimation du nombre de composantes requises
set.seed(123)
nb <- estim_ncpPCA(preproc,scale=T,method.cv = "Kfold")
preproc_impute <- imputePCA(preproc,ncp=nb$ncp,scale=T)$completeObs
```

# II. Exploration :

## II.1. Première ACP :

Dans un premier temps, nous effectuons une ACP exploratoire afin de découvrir les éventuels leviers que pourraient présenter certains individus et/ou variables.

```{r}
# 1ère PCA
res_pca1 <- PCA(preproc_impute, ncp = dim(preproc_impute)[2], scale.unit = TRUE, graph=F)
#Affichage des valeurs propres pour sélection du nombre de composantes
fviz_eig(res_pca1, addlabels = TRUE) + ggtitle("") + xlab("Composantes principales") + ylab("% d'inertie")
```

Nous récupérons 90% de la variance à partir de 6 composantes.

```{r fig.height=4}
# Diagramme des contributions des individus
fviz_pca_biplot(res_pca2,axes=c(1,2),repel = T)
ind_plot = fviz_contrib(res_pca1,axes=c(1:6),choice="ind", top = 20) + ggtitle("") + ylab("% Contribution") + coord_fixed()
# Diagramme des contributions des variables
var_plot = fviz_contrib(res_pca1,axes=c(1:6),choice="var") + ggtitle("") + ylab("% Contribution") + coord_fixed()
# Affichage des 2 diagrammes :
plot_grid(ind_plot, var_plot, labels=c("Individus", "Variables"), ncol = 2, nrow = 1, align = 'h')
```

Sur ces 7 composantes nous décidons d'ignorer les individus contribuant à plus de 5% pour la totalité de ces axes. Rien d'étonant, les stations qui contribuent fortement sont des stations hors France Métropolitaine, exemple avec Dumont d'Urville qui est une base en Antarctique.

```{r High_Contrib}
# Marquage des individus contribuant fortement
contrib_ind <-fviz_contrib(res_pca1,axes=c(1:6),choice="ind")
ind_high_contrib <- rownames(contrib_ind$data[contrib_ind$data$contrib>5,])
```

## II.2. Deuxième ACP :

Nous effectuons une nouvelle ACP en enlevant les individus ciblés. Ils ne participent pas à la construction des axes mais sont présents en bleu.

```{r Explo2}
# 2e ACP moins les individus à forte contribution
res_pca2 <- PCA(preproc_impute, ncp = dim(preproc_impute)[2], scale.unit = TRUE, graph=F,ind.sup=which(rownames(preproc_impute) %in% ind_high_contrib))
fviz_pca_biplot(res_pca2,axes=c(1,2),repel = T)
fviz_pca_biplot(res_pca2,axes=c(1,3),repel = T)
fviz_eig(res_pca2, addlabels = TRUE) + ggtitle("") + ylab("% d'inertie") + xlab("Composantes principales")
```

Nous obtenons le même résultat que la première ACP, c'est à dire que nous couvrons 90% de la variance à partir de la 6e composante.

```{r}
# Diagramme des contributions des individus
ind_plot2 = fviz_contrib(res_pca2,axes=c(1:6),choice="ind", top = 20) + ggtitle("") + ylab("% Contribution")
# Diagramme des contributions des variables
var_plot2 = fviz_contrib(res_pca2,axes=c(1:6),choice="var") + ggtitle("") + ylab("% Contribution")
# Affichage des 2 diagrammes :
plot_grid(ind_plot2, var_plot2, labels=c("Individus", "Variables"), ncol = 2, nrow = 1, align = 'h')
```

Dans l'ensemble cela reste stable et nous décidons de ne plus éliminer d'individus, car même si certaines villes contribuents fortement à la construction des axes, ces mêmes villes sont généralement localisées de manière particulière. C'est une caractéristique que l'on ne souhaite pas éliminer mais, au contraire, que l'on souhaite capturer via notre ACP.

```{r HCPC Explo2}
# HCPC pour obtenir clusters à partir la PCA
res.hcpc <- HCPC(res_pca2, graph = FALSE)
fviz_dend(res.hcpc, 
          cex = 0.7,                     # Taille du text
          palette = "jco",               # Palette de couleur ?ggpubr::ggpar
          rect = TRUE, rect_fill = TRUE, # Rectangle autour des groupes
          rect_border = "jco",           # Couleur du rectangle
          labels_track_height = 4      # Augment l'espace pour le texte
)
fviz_cluster(res.hcpc,
             repel = TRUE,            # Evite le chevauchement des textes
             show.clust.cent = TRUE, # Montre le centre des clusters
             palette = "jco",         # Palette de couleurs, voir ?ggpubr::ggpar
             ggtheme = theme_minimal(),
             main = "Factor map"
)
```

Bien que certaines villes contribuent encore fortement à la construction des axes 1 à 6, on observe sur les diagrammes ci-dessus 2 clusters principaux: un Centre-Nord France et un Sud France. Les individus contribuant fortement se retrouvent dans des clusters à part, notamment le cluster Océan Indien (Réunion + Mayotte) et un cluster composé de villes "montagnardes" (Embrun et Le Puy-Loudes), possédant une altitude relativement élevé par rapport aux autres villes présentes.

En ce qui concerne les variables, elles sont relativement bien représentées sur le cercle des corrélations et donc interprétables.

```{r}
fviz_pca_var(res_pca2,axes=c(1,2),repel=T)
fviz_pca_var(res_pca2,axes=c(1,3),repel=T)
```

On observe que les variables portant sur la température (maximale, minimale, moyenne) sont globalement et intuitivement opposées à la pression atmosphérique, la longitude, et la force du vent, ainsi que l'altitude et l'écart-type des températures moyennes dans une moindre mesure. A l'inverse, les variables portant sur la pluie semblent être déconnectées des autres variables.

En conslusion, l'ACP effectuée permet de discriminer intelligemment les individus (villes) incluent dans cette analyse, ce qui est le but souhaité lors d'une telle analyse exploratoire.

# III. Prédiction par PCR, PLSR et RandomForest

## Nettoyage et préparation des données

Tout d'abord, il conviendra de suivre le même cheminement que pour l'analyse exploratoire, toutefois en se restreignant au jeu d'apprentissage
.
```{r reload prediction}
# Re-chargement des données
climat <- fread("Données/climat.201708.csv",data.table = F)
villes <- fread("Données/postesSynop.csv",data.table=F)
climat <- merge(climat,villes,by="NUM_POSTE",all.x = T)
climat$Nom[is.na(climat$Nom)] <- "Nom Inconnu"
row.names(climat) <- climat$Nom
climat <- climat[-which(is.na(climat$FXAB)),]
# Récupération des index et du nom des villes du jeu de test
idx_test <- c(7110,7149,7222,7481,7535,7591,7630,7747,7790)
test_villes <- rownames(climat)[climat$NUM_POSTE %in% idx_test]
# Création du jeu d'apprentissage et du jeu de test
training <- climat[-which(climat$NUM_POSTE %in% idx_test),-which(colnames(climat) %in% c("NUM_POSTE","FXAB"))]
test <- climat[climat$NUM_POSTE %in% idx_test,-which(colnames(climat) %in% c("NUM_POSTE","FXAB"))]
```

Pour imputer les valeurs manquantes dans le jeu d'apprentissage, nous avons tout d'abord créé un modèle d'imputation sur ce jeu. Nous avons choisi le méthode `bagImpute` du package `caret` car il a été montré sa supériorité par rapport à d'autres méthodes d'imputation comme les KNN ou par la médiane. La fonction `preProcess()` permet de créer ce modèle d'imputation simplement, ainsi que d'éliminer les variables à faible variance. Une fois ce modèle de preprocessing obtenu, nous l'avons appliqué au jeu de test afin de l'imputer et de le formatter sur la base du jeu d'apprentissage.

```{r clean prediction}
# Sélection des variables numérique
training <- training %>% select_if(is.numeric)
# Elimination des variables contenant plus de 5% de NA
idx_bad_col <- which(apply(training,2,function(x){sum(is.na(x))})> (dim(training)[1]/20))
training <- training[,-idx_bad_col]
# Création d'un modèle de preprocessing: imputation des NA et élimination des variables à très faible variance
set.seed(123)
training_bagImpute <- preProcess(training,method=c("bagImpute","nzv"))
training <- predict(training_bagImpute,training)
test <- test[,which(colnames(test) %in% colnames(training))]
test <- predict(training_bagImpute,test)
```

Comme pour l'analyse exploratoire, nous effectuons une 1ère ACP sur le jeu d'apprentissage et récupérons les villes contribuant fortement. Cependant, nous avons avons d'une part augmenté le nombre de composantes considérées et d'autre part fixé un seuil de contribution plus faible, afin d'obtenir un groupe d'individus plus homogène.

```{r PCR, ACP explo}
# On effectue une 1ère ACP sur notre jeu d'apprentissage nettoyé
res_pca_explo <- PCA(training, ncp = dim(training)[2], scale.unit = TRUE, graph=F)
fviz_eig(res_pca_explo, addlabels = TRUE) + ggtitle("") + ylab("% d'inertie")
# 8 composantes pour 95% de la variance
contrib_explo <- fviz_contrib(res_pca_explo,axes=c(1:8),choice="ind", top = 20)
contrib_explo
high_contrib_names <- as.character(contrib_explo$data$name[contrib_explo$data$contrib > 2])
```

```{r PCR, ACP final}
# Création d'un jeu d'entrainement pour l'ACP ingorant les individus à forte contribution sur la totalité des axes 1 à 8
training_pca <- training[-which(rownames(training) %in% high_contrib_names),]
# ACP sur le jeu d'apprentissage
res_pca <- PCA(training_pca, ncp = dim(training_pca)[2], scale.unit = TRUE, graph=F)
fviz_pca_biplot(res_pca,axes=c(1,2),repel = T,col.ind = training_pca$Latitude)
res_hcpc <- HCPC(res_pca, graph = F)
fviz_dend(res_hcpc, 
          cex = 0.7,                     # Taille du text
          palette = "jco",               # Palette de couleur ?ggpubr::ggpar
          rect = TRUE, rect_fill = TRUE, # Rectangle autour des groupes
          rect_border = "jco",           # Couleur du rectangle
          labels_track_height = 3      # Augment l'espace pour le texte
)
```

La 2e ACP effectuée sur notre jeu de données d'apprentissage permet d'observer 3 clusters distincts. Un cluster Nord de la France, un cluster Sud de la France et un cluster Océan Indien. 

Dans un deuxième temps, il nous faut transformer les données de test en les standardisant puis en les projetant sur les axes obtenues par ACP sur le jeu d'entraînement. Le jeu de test est standardisé à l'aide des statistiques du jeu d'apprentissage, puis projeté sur les axes de ce même jeu d'apprentissage en récupérant la matrice de décomposition des valeurs singulières (SVD).

```{r Projection sur les axes ACP}
# Récupération de la matrice des composantes du jeu d'apprentissage
train_proj <- as.data.frame(res_pca$ind$coord)
# Standardisation du jeu de test avec les statistiques du jeu d'apprentissage
test_standard <- t(apply(test,1,function(x){(x-res_pca$call$centre)/res_pca$call$ecart.type} ))
# Projection du jeu de test standardisé sur les composantes identifiées par ACP sur le jeu d'apprentissage
test_proj <- as.data.frame(as.matrix(test_standard) %*% res_pca$svd$V)
# Récupération de la variable FXAB pour création du modèle et évaluation des prédictions sur le jeu de test plus tard
train_proj$FXAB<- climat$FXAB[which(rownames(climat) %in% rownames(train_proj))]
test_proj$FXAB <- climat$FXAB[which(rownames(climat) %in% rownames(test_proj))]
# Formattage nécessaire
colnames(test_proj) <- colnames(train_proj)
```

## Construction et évaluation d'un modèle PCR

Ensuite, nous avons construit un modèle de régression linéaire sur les composantes (PCR) grâce à la fonction `pcr` du package `pls`. Il s'agit de construire un modèle permettant de prédire la force maximale du vent en m/s du mois observé (Août).

```{r Création du modèle PCR}
set.seed(123)
pcr_fit <- pcr(FXAB ~ ., data = train_proj, scale = F, validation = "CV")
par(mfrow=c(1,1))
# Plot de la variation de la RMSE en fonction du nombre de composantes sélectionnées par le modèle PCR
plot(RMSEP(pcr_fit), legendpos = "topleft")
# Récupération du nombre optimal de composantes obtenu par cross-validation
ncomp.min <- which.min(sapply(1:dim(pcr_fit$validation$pred)[3],function(x){
  RMSE(pcr_fit$validation$pred[,,x],train_proj$FXAB)
}))
set.seed(123)
pcr_fit <- pcr(FXAB ~ ., data = train_proj,ncomp=ncomp.min, scale = F, validation = "CV")
```

Nous avons récupéré par validation croisée le nombre optimal de composantes sur lesquelles effectuer la régression. Il est maintenant possible d'appliquer notre modèle aux données de test, et avec le nombre de composantes identifié, pour en prédire la force maximale du vent.

```{r Prédiction PCR}
pred_pcr <- predict(pcr_fit, ncp = ncomp.min, newdata = test_proj) %>% as.data.frame %>% pull()
rmse_pcr <- RMSE(pred_pcr,test_proj$FXAB)
as.data.frame(pred_pcr) %>% cbind(., measured = test_proj$FXAB, villes=rownames(test_proj)) %>%
  ggplot(mapping = aes(x = measured, y = pred_pcr)) +
    geom_point() +
    geom_abline(mapping = aes(slope=1, intercept=1), color='red', linetype=2) +
    theme_bw() +
    labs(title = "Valeurs prédites en fonctions des valeurs observées (PCR)", subtitle = paste("RMSE:",round(rmse_pcr,2)),x="Observations",y="Prédictions")+geom_text_repel(aes(label=villes))
```

Nous avons obtenus une RMSE de 1.4 m/s, sur une échelle des valeurs observées s'étendant d'environ 12 m/s à 22 m/s.

## Construction et évaluation d'un modèle PLSR

Nous avons ensuite construit un modèle à l'aide de la méthode PLSR en suivant les mêmes étapes que pour la PCR puisque le package `pls` propose de passer simplement d'un méthode à l'autre en appelant identiquement la fonction `pcr()` ou `plsr()`.

```{r Création du modèle PLSR}
set.seed(123)
plsr_fit <- plsr(FXAB ~ ., data = train_proj, scale = F, validation = "CV")
par(mfrow=c(1,1))
# Plot de la variation de la RMSE en fonction du nombre de composantes sélectionnées par le modèle PLSR
plot(RMSEP(plsr_fit), legendpos = "topleft")
# Récupération du nombre optimal de composantes obtenu par cross-validation
ncomp.min <- which.min(sapply(1:dim(plsr_fit$validation$pred)[3],function(x){
  RMSE(plsr_fit$validation$pred[,,x],train_proj$FXAB)
}))
set.seed(123)
plsr_fit <- plsr(FXAB ~ ., data = train_proj,ncomp=ncomp.min, scale = F, validation = "CV")
```

```{r Prédiction PLSR}
pred_plsr <- predict(plsr_fit, ncp = ncomp.min, newdata = test_proj) %>% as.data.frame %>% pull()
rmse_plsr <- RMSE(pred_plsr,test_proj$FXAB)
as.data.frame(pred_plsr) %>% cbind(., measured = test_proj$FXAB,villes=rownames(test_proj)) %>%
  ggplot(mapping = aes(x = measured, y = pred_plsr)) +
    geom_point() +
    geom_abline(mapping = aes(slope=1, intercept=1), color='red', linetype=2) +
    theme_bw() +
    labs(title = "Valeurs prédites en fonctions des valeurs observées (PLSR)", subtitle = paste("RMSE:",round(rmse_plsr,2)),x="Observations",y="Prédictions")+geom_text_repel(aes(label=villes))
```

Ce deuxième modèle obtenu par PLSR performe légèrement moins bien que le modèle obtenu par PCR avec une RMSE de 1.91 m/s. En particulier, la ville d'Embrun et sa localisation particulière semblent avoir posé problème à ce modèle.

## Bonus 

Nous avons cherché à obtenir d'autres prédictions à l'aide de modèles simplement accessibles via le package `caret` et couramment utilisé en data science, tels que le RandomForest, le SVM et glmnet.

```{r randomForest sur Jeu de départ}
training_rf <- training[-which(rownames(training) %in% high_contrib_names),]
training_rf$FXAB <- climat$FXAB[which(rownames(climat) %in% rownames(training_rf))]
test_rf <- test
test_rf$FXAB <- climat$FXAB[which(rownames(climat) %in% rownames(test_rf))]
set.seed(123)
ctrl = trainControl(method = "repeatedcv",number=3,repeats=10)
mod_ranger <- train(FXAB~., data=training_rf, method="ranger")
mod_svm <- train(FXAB~., data=training_rf, method="svmLinear2")
mod_glmnet <- train(FXAB~., data=training_rf, method="glmnet")
RMSE(predict(mod_ranger,test_rf),test_rf$FXAB)
RMSE(predict(mod_svm,test_rf),test_rf$FXAB)
RMSE(predict(mod_glmnet,test_rf),test_rf$FXAB)
```

Ces algorithmes fournissent de bonnes prédictions de manière relativement simple, puisqu'il n'a pas été nécessaire de transformer les données par ACP et peuvent donc se présenter comme alternatives pertinentes pour faire de la prédiction sur ce genre de donées, en particulier la méthode RandomForest.

## Conclusion

La méthode PCR de régression linéaire sur les composantes s'est montré la plus efficace dans la prédiction de la force maximale du vent en Août 2017, pour les villes présentes dans le jeu de test. Cependant, les résultats obtenus sont à tempérer au vu de la taille des jeux d'apprentissage et de test.

Nous avons notamment vu que la façon dont nous préparons le jeu d'apprentissage peut avoir des répercutions considérables sur la prédiction. Ainsi, il serait nécessaire d'obtenir plus de données afin de valider le cheminement et les choix que nous avons faits, tels que le filtrage des variables sur la base du pourcentage de valeurs manquantes ou des corrélations, l'adéquation de la méthode d'imputation, ou encore le seuil à fixer pour supprimer les individus contribuant fortement à la construction des axes ACP.

